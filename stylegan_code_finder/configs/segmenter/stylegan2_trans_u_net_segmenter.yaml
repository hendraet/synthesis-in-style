# General
network: TransUNet            # The type of network to use
dataset: wpi                  # The dataset name which should be used.

# logger options
image_save_iter: 500          # How often do you want to save output images during training
image_display_iter: 500       # How often do you want to display output images during training
display_size: 16              # How many images do you want to display each time
snapshot_save_iter: 2500      # How often do you want to save trained models
log_iter: 10                  # How often do you want to log the training stats
#validation_iter: 2            # --> if you want to do evaluation in a fixed interval and not every epoch

# optimization options
#max_iter: 500000              # maximum number of training iterations
epochs: 2
batch_size: 8                 # batch size
lr: 0.01                      # lr
momentum: 0.9                 # Momentum parameter for SGD
weight_decay: 0.0001          # weight decay
end_lr: 0.00000001            # final lr for the cosine_scheduling
# cosine_max_update_epoch: 2    # After this number of epochs a CosineLRScheduler will stop decreasing the lr
cosine_max_update_iter: 4000 # After this number of iterations a CosineLRScheduler will stop decreasing the lr

# data options
num_classes: 3                  # The number of classes present in the dataset
pretrained_path: /models/trans_u_net_models/vit_checkpoint/imagenet21k/R50+ViT-B_16.npz  # path to pretrained segmentation model
input_dim: 3                  # number of image channels [1/3]
num_workers: 0                # number of data loading threads
image_size: 224               # first resize the shortest image side to this size
downsample_size: 256
num_augmentations: 5          # How many times each image should be duplicated and augmented

# network options
pretrained_model_name: R50-ViT-B_16  # Name of the pretrained model that should be used
num_skip_channels: 3          # Number of skip channels in the decoder block
vit_patch_size: 16            # for tuning the patch size of the vision transformer model
